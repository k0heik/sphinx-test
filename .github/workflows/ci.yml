# This is a basic workflow to help you get started with Actions

name: "CI"

# Controls when the action will run. Triggers the workflow on push or pull request
# events but only for the develop branch
on:
  pull_request:

# A workflow run is made up of one or more jobs that can run sequentially or in parallel
jobs:

  # This workflow contains a single job called "build"
  cpc_prediction:
    # The type of runner that the job will run on
    runs-on: ubuntu-20.04

    # Steps represent a sequence of tasks that will be executed as part of the job
    steps:
    # Checks-out your repository under $GITHUB_WORKSPACE, so your job can access it
    - uses: actions/checkout@v3.1.0
    - name: Configure AWS credential
      uses: aws-actions/configure-aws-credentials@v1-node16
      with:

        aws-access-key-id: ${{ secrets.SOPHIAAI_AWS_ACCESS_KEY_ID}}
        aws-secret-access-key: ${{ secrets.SOPHIAAI_AWS_SECRET_ACCESS_KEY }}
        aws-region: ap-northeast-1

    - name: Set up Python 3.8
      uses: actions/setup-python@v4.3.0
      with:
        python-version: 3.8
    - name: Install dependencies
      run: |
        cd cpc_prediction
        cp ../pyproject/* .
        pip install poetry==1.2.0
        poetry config virtualenvs.create false
        poetry install --with sophia-ai,main
    - name: Test with pytest
      env:
        AWS_ACCESS_KEY_ID: ${{ secrets.SOPHIAAI_AWS_ACCESS_KEY_ID}}
        AWS_SECRET_ACCESS_KEY: ${{ secrets.SOPHIAAI_AWS_SECRET_ACCESS_KEY}}
      run: |
        cd cpc_prediction
        ln -s ../common_module
        ln -s ../sophia-ai/spai spai
        ln -s ../schema
        ln -s ../deploy/.coveragerc .coveragerc
        if [ -f .env.sample ]; then export $(cat .env.sample | grep -v -E "^#|^AWS_ACCESS_KEY_ID=|^AWS_SECRET_ACCESS_KEY=" | xargs); fi
        python -m pytest tests --cache-clear --cov-config=.coveragerc --cov
    - name: Code check with flake8
      run: |
        cd cpc_prediction
        python -m flake8

  # This workflow contains a single job called "build"
  cvr_prediction:
    # The type of runner that the job will run on
    runs-on: ubuntu-20.04

    # Steps represent a sequence of tasks that will be executed as part of the job
    steps:
    # Checks-out your repository under $GITHUB_WORKSPACE, so your job can access it
    - uses: actions/checkout@v3.1.0
    - name: Configure AWS credential
      uses: aws-actions/configure-aws-credentials@v1-node16
      with:

        aws-access-key-id: ${{ secrets.SOPHIAAI_AWS_ACCESS_KEY_ID}}
        aws-secret-access-key: ${{ secrets.SOPHIAAI_AWS_SECRET_ACCESS_KEY }}
        aws-region: ap-northeast-1

    - name: Set up Python 3.8
      uses: actions/setup-python@v4.3.0
      with:
        python-version: 3.8
    - name: Install dependencies
      run: |
        cd cvr_prediction
        cp ../pyproject/* .
        pip install poetry==1.2.0
        poetry config virtualenvs.create false
        poetry install --with sophia-ai,main
    - name: Test with pytest
      env:
        AWS_ACCESS_KEY_ID: ${{ secrets.SOPHIAAI_AWS_ACCESS_KEY_ID}}
        AWS_SECRET_ACCESS_KEY: ${{ secrets.SOPHIAAI_AWS_SECRET_ACCESS_KEY}}
      run: |
        cd cvr_prediction
        ln -s ../common_module
        ln -s ../sophia-ai/spai spai
        ln -s ../schema
        ln -s ../deploy/.coveragerc .coveragerc
        if [ -f .env.sample ]; then export $(cat .env.sample | grep -v -E "^#|^AWS_ACCESS_KEY_ID=|^AWS_SECRET_ACCESS_KEY=" | xargs); fi
        python -m pytest tests --cache-clear --cov-config=.coveragerc --cov
    - name: Code check with flake8
      run: |
        cd cvr_prediction
        python -m flake8

  # This workflow contains a single job called "build"
  spa_prediction:
    # The type of runner that the job will run on
    runs-on: ubuntu-20.04

    # Steps represent a sequence of tasks that will be executed as part of the job
    steps:
    # Checks-out your repository under $GITHUB_WORKSPACE, so your job can access it
    - uses: actions/checkout@v3.1.0
    - name: Configure AWS credential
      uses: aws-actions/configure-aws-credentials@v1-node16
      with:

        aws-access-key-id: ${{ secrets.SOPHIAAI_AWS_ACCESS_KEY_ID}}
        aws-secret-access-key: ${{ secrets.SOPHIAAI_AWS_SECRET_ACCESS_KEY }}
        aws-region: ap-northeast-1

    - name: Set up Python 3.8
      uses: actions/setup-python@v4.3.0
      with:
        python-version: 3.8
    - name: Install dependencies
      run: |
        cd spa_prediction
        cp ../pyproject/* .
        pip install poetry==1.2.0
        poetry config virtualenvs.create false
        poetry install --with sophia-ai,main
    - name: Test with pytest
      env:
        AWS_ACCESS_KEY_ID: ${{ secrets.SOPHIAAI_AWS_ACCESS_KEY_ID}}
        AWS_SECRET_ACCESS_KEY: ${{ secrets.SOPHIAAI_AWS_SECRET_ACCESS_KEY}}
      run: |
        cd spa_prediction
        ln -s ../common_module
        ln -s ../sophia-ai/spai spai
        ln -s ../schema
        ln -s ../deploy/.coveragerc .coveragerc
        if [ -f .env.sample ]; then export $(cat .env.sample | grep -v -E "^#|^AWS_ACCESS_KEY_ID=|^AWS_SECRET_ACCESS_KEY=" | xargs); fi
        python -m pytest tests --cache-clear --cov-config=.coveragerc --cov
    - name: Code check with flake8
      run: |
        cd spa_prediction
        python -m flake8

  # This workflow contains a single job called "build"
  common_module:
    # The type of runner that the job will run on
    runs-on: ubuntu-20.04

    # Steps represent a sequence of tasks that will be executed as part of the job
    steps:
    # Checks-out your repository under $GITHUB_WORKSPACE, so your job can access it
    - uses: actions/checkout@v3.1.0
    - name: Configure AWS credential
      uses: aws-actions/configure-aws-credentials@v1-node16
      with:

        aws-access-key-id: ${{ secrets.SOPHIAAI_AWS_ACCESS_KEY_ID}}
        aws-secret-access-key: ${{ secrets.SOPHIAAI_AWS_SECRET_ACCESS_KEY }}
        aws-region: ap-northeast-1

    - name: Set up Python 3.8
      uses: actions/setup-python@v4.3.0
      with:
        python-version: 3.8
    - name: Install dependencies
      run: |
        cd common_module
        cp ../pyproject/* .
        pip install poetry==1.2.0
        poetry config virtualenvs.create false
        poetry install --with sophia-ai,main
    - name: Test with pytest
      env:
        AWS_ACCESS_KEY_ID: ${{ secrets.SOPHIAAI_AWS_ACCESS_KEY_ID}}
        AWS_SECRET_ACCESS_KEY: ${{ secrets.SOPHIAAI_AWS_SECRET_ACCESS_KEY}}
      run: |
        cd common_module
        ln -s ../common_module
        ln -s ../sophia-ai/spai spai
        ln -s ../schema
        ln -s ../deploy/.coveragerc .coveragerc
        if [ -f .env.sample ]; then export $(cat .env.sample | grep -v -E "^#|^AWS_ACCESS_KEY_ID=|^AWS_SECRET_ACCESS_KEY=" | xargs); fi
        python -m pytest tests --cache-clear --cov-config=.coveragerc --cov
    - name: Code check with flake8
      run: |
        cd common_module
        python -m flake8

  # This workflow contains a single job called "build"
  sophia-ai:
    # The type of runner that the job will run on
    runs-on: ubuntu-20.04

    # Steps represent a sequence of tasks that will be executed as part of the job
    steps:
    # Checks-out your repository under $GITHUB_WORKSPACE, so your job can access it
    - uses: actions/checkout@v3.1.0
    - name: Configure AWS credential
      uses: aws-actions/configure-aws-credentials@v1-node16
      with:

        aws-access-key-id: ${{ secrets.SOPHIAAI_AWS_ACCESS_KEY_ID}}
        aws-secret-access-key: ${{ secrets.SOPHIAAI_AWS_SECRET_ACCESS_KEY }}
        aws-region: ap-northeast-1

    - name: Set up Python 3.8
      uses: actions/setup-python@v4.3.0
      with:
        python-version: 3.8
    - name: Install dependencies
      run: |
        cd sophia-ai
        cp ../pyproject/* .
        pip install poetry==1.2.0
        poetry config virtualenvs.create false
        poetry install --with sophia-ai,main
    - name: Test with pytest
      env:
        AWS_ACCESS_KEY_ID: ${{ secrets.SOPHIAAI_AWS_ACCESS_KEY_ID}}
        AWS_SECRET_ACCESS_KEY: ${{ secrets.SOPHIAAI_AWS_SECRET_ACCESS_KEY}}
      run: |
        cd sophia-ai
        ln -s ../common_module
        ln -s ../sophia-ai/spai spai
        ln -s ../schema
        ln -s ../deploy/.coveragerc .coveragerc
        if [ -f .env.sample ]; then export $(cat .env.sample | grep -v -E "^#|^AWS_ACCESS_KEY_ID=|^AWS_SECRET_ACCESS_KEY=" | xargs); fi
        python -m pytest tests --cache-clear --cov-config=.coveragerc --cov
    - name: Code check with flake8
      run: |
        cd sophia-ai
        python -m flake8

  # This workflow contains a single job called "build"
  main:
    # The type of runner that the job will run on
    runs-on: ubuntu-20.04

    # Steps represent a sequence of tasks that will be executed as part of the job
    steps:
    # Checks-out your repository under $GITHUB_WORKSPACE, so your job can access it
    - uses: actions/checkout@v3.1.0
    - name: Configure AWS credential
      uses: aws-actions/configure-aws-credentials@v1-node16
      with:

        aws-access-key-id: ${{ secrets.SOPHIAAI_AWS_ACCESS_KEY_ID}}
        aws-secret-access-key: ${{ secrets.SOPHIAAI_AWS_SECRET_ACCESS_KEY }}
        aws-region: ap-northeast-1

    - name: Set up Python 3.8
      uses: actions/setup-python@v4.3.0
      with:
        python-version: 3.8
    - name: Install dependencies
      run: |
        cd main
        cp ../pyproject/* .
        pip install poetry==1.2.0
        poetry config virtualenvs.create false
        poetry install --with sophia-ai,main
    - name: Test with pytest
      env:
        AWS_ACCESS_KEY_ID: ${{ secrets.SOPHIAAI_AWS_ACCESS_KEY_ID}}
        AWS_SECRET_ACCESS_KEY: ${{ secrets.SOPHIAAI_AWS_SECRET_ACCESS_KEY}}
      run: |
        cd main
        ln -s ../common_module
        ln -s ../sophia-ai/spai spai
        ln -s ../schema
        ln -s ../deploy/.coveragerc .coveragerc
        if [ -f .env.sample ]; then export $(cat .env.sample | grep -v -E "^#|^AWS_ACCESS_KEY_ID=|^AWS_SECRET_ACCESS_KEY=" | xargs); fi
        python -m pytest tests --cache-clear --cov-config=.coveragerc --cov
    - name: Code check with flake8
      run: |
        cd main
        python -m flake8

  # This workflow contains a single job called "build"
  record_to_bq:
    # The type of runner that the job will run on
    runs-on: ubuntu-20.04

    # Steps represent a sequence of tasks that will be executed as part of the job
    steps:
    # Checks-out your repository under $GITHUB_WORKSPACE, so your job can access it
    - uses: actions/checkout@v3.1.0
    - name: Configure AWS credential
      uses: aws-actions/configure-aws-credentials@v1-node16
      with:

        aws-access-key-id: ${{ secrets.SOPHIAAI_AWS_ACCESS_KEY_ID}}
        aws-secret-access-key: ${{ secrets.SOPHIAAI_AWS_SECRET_ACCESS_KEY }}
        aws-region: ap-northeast-1

    - name: Set up Python 3.8
      uses: actions/setup-python@v4.3.0
      with:
        python-version: 3.8
    - name: Install dependencies
      run: |
        cd record_to_bq
        cp ../pyproject/* .
        pip install poetry==1.2.0
        poetry config virtualenvs.create false
        poetry install --with sophia-ai,main
    - name: Test with pytest
      env:
        AWS_ACCESS_KEY_ID: ${{ secrets.SOPHIAAI_AWS_ACCESS_KEY_ID}}
        AWS_SECRET_ACCESS_KEY: ${{ secrets.SOPHIAAI_AWS_SECRET_ACCESS_KEY}}
      run: |
        cd record_to_bq
        ln -s ../common_module
        ln -s ../sophia-ai/spai spai
        ln -s ../schema
        ln -s ../deploy/.coveragerc .coveragerc
        if [ -f .env.sample ]; then export $(cat .env.sample | grep -v -E "^#|^AWS_ACCESS_KEY_ID=|^AWS_SECRET_ACCESS_KEY=" | xargs); fi
        python -m pytest tests --cache-clear --cov-config=.coveragerc --cov
    - name: Code check with flake8
      run: |
        cd record_to_bq
        python -m flake8

  # This workflow contains a single job called "build"
  integration_test:
    # The type of runner that the job will run on
    runs-on: ubuntu-20.04

    # Steps represent a sequence of tasks that will be executed as part of the job
    steps:
    # Checks-out your repository under $GITHUB_WORKSPACE, so your job can access it
    - uses: actions/checkout@v3.1.0
    - name: Configure AWS credential
      uses: aws-actions/configure-aws-credentials@v1-node16
      with:

        aws-access-key-id: ${{ secrets.SOPHIAAI_AWS_ACCESS_KEY_ID}}
        aws-secret-access-key: ${{ secrets.SOPHIAAI_AWS_SECRET_ACCESS_KEY }}
        aws-region: ap-northeast-1

    - name: Set up Python 3.8
      uses: actions/setup-python@v4.3.0
      with:
        python-version: 3.8
    - name: Install dependencies
      run: |
        cd integration_test
        cp ../pyproject/* .
        pip install poetry==1.2.0
        poetry config virtualenvs.create false
        poetry install --with sophia-ai,main
    - name: Test with pytest
      env:
        AWS_ACCESS_KEY_ID: ${{ secrets.SOPHIAAI_AWS_ACCESS_KEY_ID}}
        AWS_SECRET_ACCESS_KEY: ${{ secrets.SOPHIAAI_AWS_SECRET_ACCESS_KEY}}
      run: |
        cd integration_test
        ln -s ../common_module
        ln -s ../sophia-ai/spai spai
        ln -s ../schema
        ln -s ../deploy/.coveragerc .coveragerc
        if [ -f .env.sample ]; then export $(cat .env.sample | grep -v -E "^#|^AWS_ACCESS_KEY_ID=|^AWS_SECRET_ACCESS_KEY=" | xargs); fi
        python -m pytest tests --cache-clear --cov-config=.coveragerc --cov
    - name: Code check with flake8
      run: |
        cd integration_test
        python -m flake8

  it_set_uuid:
    runs-on: ubuntu-20.04
    steps:
    - uses: actions/checkout@v3.1.0
    - name: set .env.base
      run: |
        cd integration_test
        export UUID=$(uuidgen | sed -e 's/-//g')
        cat .env.sample \
        | sed "s:DATASET_NAME=.*$:DATASET_NAME=bid_optimisation_ml_test_${UUID}:" \
        | sed "s:COMMERCE_FLOW_DATASET_NAME=.*$:COMMERCE_FLOW_DATASET_NAME=bid_optimisation_ml_test_${UUID}_commerce_flow:" \
        | sed "s:WORKING_DATASET_NAME=.*$:WORKING_DATASET_NAME=bid_optimisation_ml_test_${UUID}_work:" \
        >> .env.base
    - uses: actions/upload-artifact@v3.1.1
      with:
        name: ${{ github.run_number }}-.env.base
        path: integration_test/.env.base
  it_prepare_testdata:
    runs-on: ubuntu-20.04
    needs: it_set_uuid
    steps:
    - uses: actions/checkout@v3.1.0
    - uses: actions/download-artifact@v3.0.1
      with:
        name: ${{ github.run_number }}-.env.base
        path: integration_test
    - name: Set .env
      env:

        AWS_ACCESS_KEY_ID: ${{ secrets.SOPHIAAI_AWS_ACCESS_KEY_ID}}
        AWS_SECRET_ACCESS_KEY: ${{ secrets.SOPHIAAI_AWS_SECRET_ACCESS_KEY}}

      run: |
        cd integration_test
        cat .env.base \
        | sed "s:AWS_ACCESS_KEY_ID=.*$:AWS_ACCESS_KEY_ID=${AWS_ACCESS_KEY_ID}:" \
        | sed "s:AWS_SECRET_ACCESS_KEY=.*$:AWS_SECRET_ACCESS_KEY=${AWS_SECRET_ACCESS_KEY}:" \
        >> .env
    - name: Configure AWS credential
      uses: aws-actions/configure-aws-credentials@v1-node16
      with:

        aws-access-key-id: ${{ secrets.SOPHIAAI_AWS_ACCESS_KEY_ID}}
        aws-secret-access-key: ${{ secrets.SOPHIAAI_AWS_SECRET_ACCESS_KEY }}
        aws-region: ap-northeast-1

    - name: Set up Python 3.8
      uses: actions/setup-python@v4.3.0
      with:
        python-version: 3.8
    - name: Install dependencies
      run: |
        cd integration_test
        python -m pip install --upgrade pip wheel
        pip install flake8 pytest pytest-cov pytest-mock
        if [ -f requirements.txt ]; then pip install -r requirements.txt; fi
    - name: Prepare test data
      run: |
        cd integration_test
        inv reset-dataset
        inv create-all-tables
        inv prepare-test-data

  build_cpc_prediction:
    runs-on: ubuntu-20.04
    env:
      DOCKER_BUILDKIT: '1'
    needs: it_set_uuid
    steps:
    - uses: actions/checkout@v3.1.0
    - uses: actions/download-artifact@v3.0.1
      with:
        name: ${{ github.run_number }}-.env.base
        path: integration_test
    - name: Set .env
      env:

        AWS_ACCESS_KEY_ID: ${{ secrets.SOPHIAAI_AWS_ACCESS_KEY_ID}}
        AWS_SECRET_ACCESS_KEY: ${{ secrets.SOPHIAAI_AWS_SECRET_ACCESS_KEY}}

      run: |
        cd integration_test
        cat .env.base \
        | sed "s:AWS_ACCESS_KEY_ID=.*$:AWS_ACCESS_KEY_ID=${AWS_ACCESS_KEY_ID}:" \
        | sed "s:AWS_SECRET_ACCESS_KEY=.*$:AWS_SECRET_ACCESS_KEY=${AWS_SECRET_ACCESS_KEY}:" \
        >> .env
    - name: Configure AWS credential
      uses: aws-actions/configure-aws-credentials@v1-node16
      with:

        aws-access-key-id: ${{ secrets.SOPHIAAI_AWS_ACCESS_KEY_ID}}
        aws-secret-access-key: ${{ secrets.SOPHIAAI_AWS_SECRET_ACCESS_KEY }}
        aws-region: ap-northeast-1

    - name: Set up Python 3.8
      uses: actions/setup-python@v4.3.0
      with:
        python-version: 3.8
    - name: Install dependencies
      run: |
        cd integration_test
        python -m pip install --upgrade pip wheel
        pip install flake8 pytest pytest-cov pytest-mock
        if [ -f requirements.txt ]; then pip install -r requirements.txt; fi
    - name: Build a container
      run: |
        cd integration_test
        inv build-container-by-name cpc_prediction
        docker save cpc_prediction | gzip -c > cpc_prediction.tar.gz
    - uses: actions/upload-artifact@v3.1.1
      with:
        name: ${{ github.run_number }}-tarball-cpc_prediction
        path: integration_test/cpc_prediction.tar.gz

  build_cvr_prediction:
    runs-on: ubuntu-20.04
    env:
      DOCKER_BUILDKIT: '1'
    needs: it_set_uuid
    steps:
    - uses: actions/checkout@v3.1.0
    - uses: actions/download-artifact@v3.0.1
      with:
        name: ${{ github.run_number }}-.env.base
        path: integration_test
    - name: Set .env
      env:

        AWS_ACCESS_KEY_ID: ${{ secrets.SOPHIAAI_AWS_ACCESS_KEY_ID}}
        AWS_SECRET_ACCESS_KEY: ${{ secrets.SOPHIAAI_AWS_SECRET_ACCESS_KEY}}

      run: |
        cd integration_test
        cat .env.base \
        | sed "s:AWS_ACCESS_KEY_ID=.*$:AWS_ACCESS_KEY_ID=${AWS_ACCESS_KEY_ID}:" \
        | sed "s:AWS_SECRET_ACCESS_KEY=.*$:AWS_SECRET_ACCESS_KEY=${AWS_SECRET_ACCESS_KEY}:" \
        >> .env
    - name: Configure AWS credential
      uses: aws-actions/configure-aws-credentials@v1-node16
      with:

        aws-access-key-id: ${{ secrets.SOPHIAAI_AWS_ACCESS_KEY_ID}}
        aws-secret-access-key: ${{ secrets.SOPHIAAI_AWS_SECRET_ACCESS_KEY }}
        aws-region: ap-northeast-1

    - name: Set up Python 3.8
      uses: actions/setup-python@v4.3.0
      with:
        python-version: 3.8
    - name: Install dependencies
      run: |
        cd integration_test
        python -m pip install --upgrade pip wheel
        pip install flake8 pytest pytest-cov pytest-mock
        if [ -f requirements.txt ]; then pip install -r requirements.txt; fi
    - name: Build a container
      run: |
        cd integration_test
        inv build-container-by-name cvr_prediction
        docker save cvr_prediction | gzip -c > cvr_prediction.tar.gz
    - uses: actions/upload-artifact@v3.1.1
      with:
        name: ${{ github.run_number }}-tarball-cvr_prediction
        path: integration_test/cvr_prediction.tar.gz

  build_spa_prediction:
    runs-on: ubuntu-20.04
    env:
      DOCKER_BUILDKIT: '1'
    needs: it_set_uuid
    steps:
    - uses: actions/checkout@v3.1.0
    - uses: actions/download-artifact@v3.0.1
      with:
        name: ${{ github.run_number }}-.env.base
        path: integration_test
    - name: Set .env
      env:

        AWS_ACCESS_KEY_ID: ${{ secrets.SOPHIAAI_AWS_ACCESS_KEY_ID}}
        AWS_SECRET_ACCESS_KEY: ${{ secrets.SOPHIAAI_AWS_SECRET_ACCESS_KEY}}

      run: |
        cd integration_test
        cat .env.base \
        | sed "s:AWS_ACCESS_KEY_ID=.*$:AWS_ACCESS_KEY_ID=${AWS_ACCESS_KEY_ID}:" \
        | sed "s:AWS_SECRET_ACCESS_KEY=.*$:AWS_SECRET_ACCESS_KEY=${AWS_SECRET_ACCESS_KEY}:" \
        >> .env
    - name: Configure AWS credential
      uses: aws-actions/configure-aws-credentials@v1-node16
      with:

        aws-access-key-id: ${{ secrets.SOPHIAAI_AWS_ACCESS_KEY_ID}}
        aws-secret-access-key: ${{ secrets.SOPHIAAI_AWS_SECRET_ACCESS_KEY }}
        aws-region: ap-northeast-1

    - name: Set up Python 3.8
      uses: actions/setup-python@v4.3.0
      with:
        python-version: 3.8
    - name: Install dependencies
      run: |
        cd integration_test
        python -m pip install --upgrade pip wheel
        pip install flake8 pytest pytest-cov pytest-mock
        if [ -f requirements.txt ]; then pip install -r requirements.txt; fi
    - name: Build a container
      run: |
        cd integration_test
        inv build-container-by-name spa_prediction
        docker save spa_prediction | gzip -c > spa_prediction.tar.gz
    - uses: actions/upload-artifact@v3.1.1
      with:
        name: ${{ github.run_number }}-tarball-spa_prediction
        path: integration_test/spa_prediction.tar.gz

  build_main:
    runs-on: ubuntu-20.04
    env:
      DOCKER_BUILDKIT: '1'
    needs: it_set_uuid
    steps:
    - uses: actions/checkout@v3.1.0
    - uses: actions/download-artifact@v3.0.1
      with:
        name: ${{ github.run_number }}-.env.base
        path: integration_test
    - name: Set .env
      env:

        AWS_ACCESS_KEY_ID: ${{ secrets.SOPHIAAI_AWS_ACCESS_KEY_ID}}
        AWS_SECRET_ACCESS_KEY: ${{ secrets.SOPHIAAI_AWS_SECRET_ACCESS_KEY}}

      run: |
        cd integration_test
        cat .env.base \
        | sed "s:AWS_ACCESS_KEY_ID=.*$:AWS_ACCESS_KEY_ID=${AWS_ACCESS_KEY_ID}:" \
        | sed "s:AWS_SECRET_ACCESS_KEY=.*$:AWS_SECRET_ACCESS_KEY=${AWS_SECRET_ACCESS_KEY}:" \
        >> .env
    - name: Configure AWS credential
      uses: aws-actions/configure-aws-credentials@v1-node16
      with:

        aws-access-key-id: ${{ secrets.SOPHIAAI_AWS_ACCESS_KEY_ID}}
        aws-secret-access-key: ${{ secrets.SOPHIAAI_AWS_SECRET_ACCESS_KEY }}
        aws-region: ap-northeast-1

    - name: Set up Python 3.8
      uses: actions/setup-python@v4.3.0
      with:
        python-version: 3.8
    - name: Install dependencies
      run: |
        cd integration_test
        python -m pip install --upgrade pip wheel
        pip install flake8 pytest pytest-cov pytest-mock
        if [ -f requirements.txt ]; then pip install -r requirements.txt; fi
    - name: Build a container
      run: |
        cd integration_test
        inv build-container-by-name main
        docker save main | gzip -c > main.tar.gz
    - uses: actions/upload-artifact@v3.1.1
      with:
        name: ${{ github.run_number }}-tarball-main
        path: integration_test/main.tar.gz

  build_record_to_bq:
    runs-on: ubuntu-20.04
    env:
      DOCKER_BUILDKIT: '1'
    needs: it_set_uuid
    steps:
    - uses: actions/checkout@v3.1.0
    - uses: actions/download-artifact@v3.0.1
      with:
        name: ${{ github.run_number }}-.env.base
        path: integration_test
    - name: Set .env
      env:

        AWS_ACCESS_KEY_ID: ${{ secrets.SOPHIAAI_AWS_ACCESS_KEY_ID}}
        AWS_SECRET_ACCESS_KEY: ${{ secrets.SOPHIAAI_AWS_SECRET_ACCESS_KEY}}

      run: |
        cd integration_test
        cat .env.base \
        | sed "s:AWS_ACCESS_KEY_ID=.*$:AWS_ACCESS_KEY_ID=${AWS_ACCESS_KEY_ID}:" \
        | sed "s:AWS_SECRET_ACCESS_KEY=.*$:AWS_SECRET_ACCESS_KEY=${AWS_SECRET_ACCESS_KEY}:" \
        >> .env
    - name: Configure AWS credential
      uses: aws-actions/configure-aws-credentials@v1-node16
      with:

        aws-access-key-id: ${{ secrets.SOPHIAAI_AWS_ACCESS_KEY_ID}}
        aws-secret-access-key: ${{ secrets.SOPHIAAI_AWS_SECRET_ACCESS_KEY }}
        aws-region: ap-northeast-1

    - name: Set up Python 3.8
      uses: actions/setup-python@v4.3.0
      with:
        python-version: 3.8
    - name: Install dependencies
      run: |
        cd integration_test
        python -m pip install --upgrade pip wheel
        pip install flake8 pytest pytest-cov pytest-mock
        if [ -f requirements.txt ]; then pip install -r requirements.txt; fi
    - name: Build a container
      run: |
        cd integration_test
        inv build-container-by-name record_to_bq
        docker save record_to_bq | gzip -c > record_to_bq.tar.gz
    - uses: actions/upload-artifact@v3.1.1
      with:
        name: ${{ github.run_number }}-tarball-record_to_bq
        path: integration_test/record_to_bq.tar.gz

  run_it:
    env:
      DOCKER_BUILDKIT: '1'
    runs-on: ubuntu-20.04
    needs: [build_cpc_prediction, build_cvr_prediction, build_spa_prediction, build_main, build_record_to_bq, it_prepare_testdata]
    # Steps represent a sequence of tasks that will be executed as part of the job
    steps:
    # Checks-out your repository under $GITHUB_WORKSPACE, so your job can access it
    - uses: actions/checkout@v3.1.0
    - uses: actions/download-artifact@v3.0.1
      with:
        name: ${{ github.run_number }}-.env.base
        path: integration_test
    - name: Set .env
      env:

        AWS_ACCESS_KEY_ID: ${{ secrets.SOPHIAAI_AWS_ACCESS_KEY_ID}}
        AWS_SECRET_ACCESS_KEY: ${{ secrets.SOPHIAAI_AWS_SECRET_ACCESS_KEY}}

      run: |
        cd integration_test
        cat .env.base \
        | sed "s:AWS_ACCESS_KEY_ID=.*$:AWS_ACCESS_KEY_ID=${AWS_ACCESS_KEY_ID}:" \
        | sed "s:AWS_SECRET_ACCESS_KEY=.*$:AWS_SECRET_ACCESS_KEY=${AWS_SECRET_ACCESS_KEY}:" \
        >> .env
    - name: Configure AWS credential
      uses: aws-actions/configure-aws-credentials@v1-node16
      with:

        aws-access-key-id: ${{ secrets.SOPHIAAI_AWS_ACCESS_KEY_ID}}
        aws-secret-access-key: ${{ secrets.SOPHIAAI_AWS_SECRET_ACCESS_KEY }}
        aws-region: ap-northeast-1

    - name: Set up Python 3.8
      uses: actions/setup-python@v4.3.0
      with:
        python-version: 3.8
    - name: Install dependencies
      run: |
        cd integration_test
        python -m pip install --upgrade pip wheel
        pip install flake8 pytest pytest-cov pytest-mock
        if [ -f requirements.txt ]; then pip install -r requirements.txt; fi
    - name: mkdir tmp dir
      run: |
        mkdir tarballs

    - uses: actions/download-artifact@v3.0.1
      with:
        name: ${{ github.run_number }}-tarball-cpc_prediction
        path: tarballs
    - uses: actions/download-artifact@v3.0.1
      with:
        name: ${{ github.run_number }}-tarball-cvr_prediction
        path: tarballs
    - uses: actions/download-artifact@v3.0.1
      with:
        name: ${{ github.run_number }}-tarball-spa_prediction
        path: tarballs
    - uses: actions/download-artifact@v3.0.1
      with:
        name: ${{ github.run_number }}-tarball-main
        path: tarballs
    - uses: actions/download-artifact@v3.0.1
      with:
        name: ${{ github.run_number }}-tarball-record_to_bq
        path: tarballs
    - name: Load Builded Containers
      run: |

        cat tarballs/cpc_prediction.tar.gz | gzip -d | docker load 
        cat tarballs/cvr_prediction.tar.gz | gzip -d | docker load 
        cat tarballs/spa_prediction.tar.gz | gzip -d | docker load 
        cat tarballs/main.tar.gz | gzip -d | docker load 
        cat tarballs/record_to_bq.tar.gz | gzip -d | docker load 
    - name: Run Integration Test
      run: |
        cd integration_test
        bash run_it.sh
  delete_test_dataset_and_artifacts:
    env:
      DOCKER_BUILDKIT: '1'
    runs-on: ubuntu-20.04
    if: always()
    needs: [it_prepare_testdata, run_it]
    # Steps represent a sequence of tasks that will be executed as part of the job
    steps:
    # Checks-out your repository under $GITHUB_WORKSPACE, so your job can access it
    - uses: actions/checkout@v3.1.0
    - uses: actions/download-artifact@v3.0.1
      with:
        name: ${{ github.run_number }}-.env.base
        path: integration_test
    - name: Set .env
      env:

        AWS_ACCESS_KEY_ID: ${{ secrets.SOPHIAAI_AWS_ACCESS_KEY_ID}}
        AWS_SECRET_ACCESS_KEY: ${{ secrets.SOPHIAAI_AWS_SECRET_ACCESS_KEY}}

      run: |
        cd integration_test
        cat .env.base \
        | sed "s:AWS_ACCESS_KEY_ID=.*$:AWS_ACCESS_KEY_ID=${AWS_ACCESS_KEY_ID}:" \
        | sed "s:AWS_SECRET_ACCESS_KEY=.*$:AWS_SECRET_ACCESS_KEY=${AWS_SECRET_ACCESS_KEY}:" \
        >> .env
    - name: Configure AWS credential
      uses: aws-actions/configure-aws-credentials@v1-node16
      with:

        aws-access-key-id: ${{ secrets.SOPHIAAI_AWS_ACCESS_KEY_ID}}
        aws-secret-access-key: ${{ secrets.SOPHIAAI_AWS_SECRET_ACCESS_KEY }}
        aws-region: ap-northeast-1

    - name: Set up Python 3.8
      uses: actions/setup-python@v4.3.0
      with:
        python-version: 3.8
    - name: Install dependencies
      run: |
        cd integration_test
        python -m pip install --upgrade pip wheel
        pip install flake8 pytest pytest-cov pytest-mock
        if [ -f requirements.txt ]; then pip install -r requirements.txt; fi
    - name: Clean up
      run: |
        cd integration_test
        inv delete-dataset
    - uses: geekyeggo/delete-artifact@v2.0.0
      with:
        name: |
          ${{ github.run_number }}-.env.base

          ${{ github.run_number }}-tarball-cpc_prediction
          ${{ github.run_number }}-tarball-cvr_prediction
          ${{ github.run_number }}-tarball-spa_prediction
          ${{ github.run_number }}-tarball-main
          ${{ github.run_number }}-tarball-record_to_bq
  slack_notify_success:
    runs-on: ubuntu-20.04
    if: always()
    needs: [cpc_prediction, cvr_prediction, spa_prediction, common_module, sophia-ai, main, record_to_bq, integration_test, run_it]
    steps:
    - uses: actions/checkout@v3.1.0
    - uses: technote-space/workflow-conclusion-action@v3.0.2
    - name: Set COMMIT_MESSAGE
      run: echo "COMMIT_MESSAGE=$(echo ${{ github.event.head_commit.message }} | tr '\n' ' '|tr '\"' ' ' )" >> $GITHUB_ENV
    - name: Slack Notification on SUCCESS
      uses: slackapi/slack-github-action@v1.23.0
      env:
        SLACK_WEBHOOK_URL: ${{ secrets.SOPHIAAI_SLACK_WEBHOOK_URL }}
        SLACK_WEBHOOK_TYPE: INCOMING_WEBHOOK
      with:
        payload: |
          {
            "text": "Successfully.",
            "attachments": [
              {
                "color": "good",
                "author_name": "${{ github.actor }}",
                "author_icon": "${{ github.event.sender.avatar_url }}",
                "fields": [
                  {
                    "title": "GitHub Actions URL",
                    "value": "${{ github.event.repository.html_url }}/actions/runs/${{ github.run_id }}"
                  }
                ]
              }
            ]
          }
      if: env.WORKFLOW_CONCLUSION == 'success'

  slack_notify_failure:
    runs-on: ubuntu-20.04
    if: always()
    needs: [cpc_prediction, cvr_prediction, spa_prediction, common_module, sophia-ai, main, record_to_bq, integration_test, run_it]
    steps:
    - uses: actions/checkout@v3.1.0
    - uses: technote-space/workflow-conclusion-action@v3.0.2
    - name: Set COMMIT_MESSAGE
      run: echo "COMMIT_MESSAGE=$(echo ${{ github.event.head_commit.message }} | tr '\n' ' '|tr '\"' ' ' )" >> $GITHUB_ENV
    - name: Slack Notification on FAILED
      uses: slackapi/slack-github-action@v1.23.0
      env:
        SLACK_WEBHOOK_URL: ${{ secrets.SOPHIAAI_SLACK_WEBHOOK_URL }}
        SLACK_WEBHOOK_TYPE: INCOMING_WEBHOOK
      with:
        payload: |
          {
            "text": "Failed.",
            "attachments": [
              {
                "color": "danger",
                "author_name": "${{ github.actor }}",
                "author_icon": "${{ github.event.sender.avatar_url }}",
                "fields": [
                  {
                    "title": "GitHub Actions URL",
                    "value": "${{ github.event.repository.html_url }}/actions/runs/${{ github.run_id }}"
                  }
                ]
              }
            ]
          }
      if: env.WORKFLOW_CONCLUSION == 'failure'
